{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_tf.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncfMpJIZo_Mo",
        "outputId": "49ddd822-98fa-41b4-b204-6e321cd432ef"
      },
      "source": [
        "from collections import UserList\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import random\r\n",
        "import tqdm\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "\r\n",
        "import datetime\r\n",
        "import copy\r\n",
        "import time\r\n",
        "\r\n",
        "# from tf_environment import *\r\n",
        "# from comet_ml import Experiment\r\n",
        "\r\n",
        "# experiment = Experiment(\"HsbMT2nT816RPUXC1LLkVvEe0\")\r\n",
        "\r\n",
        "now = datetime.datetime.now()\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')\r\n",
        "\r\n",
        "import sys\r\n",
        "sys.path.append('drive/My Drive/Colab Notebooks/distributed_AoI_exp1/')\r\n",
        "\r\n",
        "!pwd\r\n",
        "!pip install tf-agents\r\n",
        "!pip install dm-reverb[tensorflow]\r\n",
        "\r\n",
        "from create_graph_1 import *\r\n",
        "# from path_loss_probability import *\r\n",
        "import itertools\r\n",
        "from itertools import product  \r\n",
        "from tf_reinforce import *\r\n",
        "from tf_dqn import *\r\n",
        "from tf_c51 import *\r\n",
        "from tf_sac import *\r\n",
        "from random_scheduling import *\r\n",
        "from greedy_scheduling import *\r\n",
        "from mad_scheduling import *\r\n",
        "\r\n",
        "import sys\r\n",
        "\r\n",
        "from joblib import Parallel, delayed\r\n",
        "import multiprocessing as mp\r\n",
        "\r\n",
        "from parameters import *\r\n",
        "\r\n",
        "random.seed(42)\r\n",
        "# tf.random.set_seed(42)\r\n",
        "\r\n",
        "def distributed_run(arguments):\r\n",
        "  \r\n",
        "    print(f\"passed arguments are {arguments}\\n\", file = open(folder_name + \"/results.txt\", \"a\"), flush = True)\r\n",
        "    print(f\"passed arguments are {arguments}\")\r\n",
        "\r\n",
        "    # pool.starmap(do_scheduling, [(arg[0], arg[1], arg[2]) for arg in arguments]) ## this enable multiprocessing but I am getting memroy allocation and other CUDA related errors with this, so now using sequential execution\r\n",
        "    \r\n",
        "    for j in arguments:\r\n",
        "        do_scheduling(j[0],j[1],j[2])\r\n",
        "    \r\n",
        "#############################################################\r\n",
        "\r\n",
        "def do_scheduling(deployment, I, scheduler):\r\n",
        "    \r\n",
        "    \r\n",
        "    deployment_options = [\"MDS\", \"RP\"]\r\n",
        "    scheduler_options  = [\"random\", \"greedy\", \"MAD\", \"dqn\", \"c51\", \"sac\"]\r\n",
        "    assert(deployment in deployment_options and scheduler in scheduler_options)\r\n",
        "\r\n",
        "    random.seed(42) ## this seed ensures same location of users in every case, keep both seeds\r\n",
        "    \r\n",
        "    if test_case:\r\n",
        "        \r\n",
        "        ## exp 24\r\n",
        "        print(f\"under experiment {experiment}\", file = open(folder_name + \"/results.txt\", \"a\"), flush = True)\r\n",
        "\r\n",
        "        drones_needed           = 1\r\n",
        "        users_per_drone         = [3]\r\n",
        "        # adj_matrix              = np.array([[0, 1, 1, 0, 0],\r\n",
        "        #                                     [0, 0, 1, 1, 0],\r\n",
        "        #                                     [0, 0, 0, 1, 1],\r\n",
        "        #                                     [1, 0, 0, 0, 1],\r\n",
        "        #                                     [1, 1, 0, 0, 0]])\r\n",
        "        adj_matrix              = np.array([[0, 1, 1],\r\n",
        "                                            [1, 0, 1],\r\n",
        "                                            [1, 1, 0]])\r\n",
        "        \r\n",
        "        tx_rx_pairs = []\r\n",
        "        tx_users    = []\r\n",
        "        \r\n",
        "        rows, columns = np.shape(adj_matrix)\r\n",
        "        # print(f\"rows = {rows}, columns = {columns}\")\r\n",
        "        \r\n",
        "        ## relevant pair calculation starts\r\n",
        "        \r\n",
        "        # age at the final dest will be w.r.t only these pairs.  \r\n",
        "        for i in range(rows):\r\n",
        "            for ii in range(columns):\r\n",
        "                if adj_matrix[i,ii]==1:\r\n",
        "                    pair = [i + 10, ii + 10] ## 10 as count is 10 from main_tf.py where user IDs start from 10\r\n",
        "                    tx_rx_pairs.append(pair)\r\n",
        "        \r\n",
        "        for i in tx_rx_pairs:\r\n",
        "            if i[0] not in tx_users:\r\n",
        "                tx_users.append(i[0])\r\n",
        "        assert drones_needed    ==len(users_per_drone)\r\n",
        "        \r\n",
        "        drones_coverage         = []\r\n",
        "        \r\n",
        "        count = 10 # user IDs will start from this. and this also ensured that UAV and users have different IDs. Ensure number of UAVs is less than the count\r\n",
        "        for i in range(drones_needed):\r\n",
        "            individual_drone_coverage = [x for x in range(count, count + users_per_drone[i])]\r\n",
        "            print(f\"individual_drone_coverage = {individual_drone_coverage}\", file = open(folder_name + \"/results.txt\", \"a\"), flush = True)\r\n",
        "            count = individual_drone_coverage[-1] + 1\r\n",
        "            drones_coverage.append(individual_drone_coverage)\r\n",
        "            \r\n",
        "        user_list = []\r\n",
        "        UAV_list = np.arange(drones_needed)\r\n",
        "        for i in drones_coverage:\r\n",
        "            for j in i:\r\n",
        "                if j!=0: ## user will not contain 0\r\n",
        "                    user_list.append(j)\r\n",
        "        \r\n",
        "        print(f\"user_list = {user_list}, UAV_list = {UAV_list}\", file = open(folder_name + \"/results.txt\", \"a\"), flush = True)\r\n",
        "        assert (max(user_list) - min(user_list))+1 == sum(users_per_drone)\r\n",
        "        # time.sleep(10)\r\n",
        "\r\n",
        "                    \r\n",
        "        if periodic_generation:\r\n",
        "            periodicity = {10:2,11:3,12:4,13:2,14:3} #{x:random.choice([2,3,4]) for x in user_list}\r\n",
        "        else:\r\n",
        "            periodicity = {x:1 for x in user_list}\r\n",
        "        \r\n",
        "        I = len(user_list) # changed to the needed value\r\n",
        "\r\n",
        "        if packet_loss == True:\r\n",
        "            packet_update_loss  = {tuple(yy) : round(random.random(),2) for yy in tx_rx_pairs}\r\n",
        "            packet_sample_loss  = {yy : round(random.random(),2) for yy in user_list}\r\n",
        "        else:\r\n",
        "            packet_update_loss  = {tuple(yy) : -1 for yy in tx_rx_pairs}\r\n",
        "            packet_sample_loss  = {yy : -1 for yy in user_list}\r\n",
        "            \r\n",
        "    else: ## user defined UAV and user configuration\r\n",
        "        \r\n",
        "        assert test_case == True, \"Test Case has to be true here\" # denominator can't be 0 \r\n",
        "                        \r\n",
        "        # I is number of users, L length and B breadth\r\n",
        "        x_vals = random.sample(range(1, L-1), I) # x-coordinates for users\r\n",
        "        y_vals = random.sample(range(1, B-1), I) # y-coordinates for users\r\n",
        "        z_vals = [0]*I\r\n",
        "\r\n",
        "        user_coordinates = list(zip(x_vals,y_vals))\r\n",
        "\r\n",
        "        x_grid_nos = int(L/r) + 1 # number of different values the grid takes for x axis\r\n",
        "        y_grid_nos = int(B/r) + 1 # number of different values the grid takes for y axis\r\n",
        "\r\n",
        "        grid_x = np.linspace(0, L, num = x_grid_nos) # generate evenly spaced x positions for grid\r\n",
        "        grid_y = np.linspace(0, B, num = y_grid_nos) # generate evenly spaced y positions for grid\r\n",
        "        \r\n",
        "        grid_coordinates = list(itertools.product(grid_x , grid_y))\r\n",
        "\r\n",
        "        drones_needed, drones_coverage = create_graph_1(user_coordinates, grid_coordinates, deployment)       \r\n",
        "    \r\n",
        "        user_list = [] ## this is not the same user_list as defined in the environment, this is just used to index the packet loss and sample loss\r\n",
        "        UAV_list  = np.arange(drones_needed)\r\n",
        "        \r\n",
        "        for i in drones_coverage:\r\n",
        "            for j in i:\r\n",
        "                if j!=0:\r\n",
        "                    user_list.append(j)\r\n",
        "                    \r\n",
        "         \r\n",
        "        if periodic_generation:\r\n",
        "            periodicity = {x:random.choice([2,3,4]) for x in user_list}\r\n",
        "        else:\r\n",
        "            periodicity = {x:1 for x in user_list}\r\n",
        "\r\n",
        "\r\n",
        "        if packet_loss == True:\r\n",
        "            packet_update_loss = {yy : round(random.random(),2) for yy in user_list}\r\n",
        "            packet_sample_loss = {yy : round(random.random(),2) for yy in user_list}\r\n",
        "        else:\r\n",
        "            packet_update_loss = {yy : -1 for yy in user_list}\r\n",
        "            packet_sample_loss = {yy : -1 for yy in user_list}\r\n",
        "            \r\n",
        "\r\n",
        "    print(f\"\\n\\n{deployment} deployment for {I} users under {scheduler} scheduling\\n\", file=open(folder_name + \"/results.txt\", \"a\"), flush=True)\r\n",
        "\r\n",
        "            \r\n",
        "    print(f'Under test_case = {test_case}, drones_needed = {drones_needed}, UAV_list = {UAV_list}, drones_coverage = {drones_coverage}, user_list = {user_list}, periodicity = {periodicity} for {deployment} deployment for {I} users under {scheduler} scheduling, update loss = {packet_update_loss}, sampling loss = {packet_sample_loss}, user_list = {user_list}, UAV_list = {UAV_list}, CSI_as_state = {CSI_as_state}, sample_error_in_CSI = {sample_error_in_CSI}\\n', file=open(folder_name + \"/results.txt\", \"a\"), flush=True)  \r\n",
        "    \r\n",
        "\r\n",
        "    str_x = str(deployment) + \" placement with \" + str(I) + \" users needs \" + str(scheduler) + \" scheduler and \"  + str(drones_needed) + \" drones\\n\"\r\n",
        "    print(f'{str_x}', file=open(folder_name + \"/drones.txt\", \"a\"), flush=True)\r\n",
        "    \r\n",
        "    \r\n",
        "    if scheduler == \"greedy\":\r\n",
        "        t1 = time.time()\r\n",
        "        #with tf.device('/CPU:0'):\r\n",
        "        greedy_overall[I], greedy_final[I], greedy_all_actions[I] = greedy_scheduling(I, drones_coverage, folder_name, deployment, packet_update_loss, packet_sample_loss, periodicity, adj_matrix, tx_rx_pairs, tx_users)  \r\n",
        "        t2 = time.time()\r\n",
        "        print(\"greedy for \", I, \" users took \", t2-t1, \" seconds to complete\", file=open(folder_name + \"/results.txt\", \"a\"), flush=True)\r\n",
        "        pickle.dump(greedy_overall, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_greedy_overall.pickle\", \"wb\")) \r\n",
        "        pickle.dump(greedy_final, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_greedy_final.pickle\", \"wb\"))\r\n",
        "        pickle.dump(greedy_all_actions, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"_greedy_all_actions.pickle\", \"wb\")) \r\n",
        "    \r\n",
        "    if scheduler == \"random\":\r\n",
        "        t1 = time.time()\r\n",
        "        #with tf.device('/CPU:0'):\r\n",
        "        random_overall[I], random_final[I], random_all_actions[I] = random_scheduling(I, drones_coverage, folder_name, deployment, packet_update_loss, packet_sample_loss, periodicity, adj_matrix, tx_rx_pairs, tx_users)\r\n",
        "        t2 = time.time()\r\n",
        "        print(\"random for \", I, \" users took \", t2-t1, \" seconds to complete\", file=open(folder_name + \"/results.txt\", \"a\"), flush=True)\r\n",
        "        pickle.dump(random_overall, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_random_overall.pickle\", \"wb\")) \r\n",
        "        pickle.dump(random_final, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_random_final.pickle\", \"wb\")) \r\n",
        "        pickle.dump(random_all_actions, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_random_all_actions.pickle\", \"wb\")) \r\n",
        "        \r\n",
        "        \r\n",
        "    if scheduler == \"MAD\":\r\n",
        "        t1 = time.time()\r\n",
        "        #with tf.device('/CPU:0'):\r\n",
        "        mad_overall[I], mad_final[I], mad_all_actions[I] = mad_scheduling(I, drones_coverage, folder_name, deployment, packet_update_loss, packet_sample_loss, periodicity, adj_matrix, tx_rx_pairs, tx_users)\r\n",
        "        t2 = time.time()\r\n",
        "        print(\"MAD for \", I, \" users took \", t2-t1, \" seconds to complete\", file=open(folder_name + \"/results.txt\", \"a\"), flush=True)\r\n",
        "        pickle.dump(mad_overall, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_mad_overall.pickle\", \"wb\")) \r\n",
        "        pickle.dump(mad_final, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_mad_final.pickle\", \"wb\"))\r\n",
        "        pickle.dump(mad_all_actions, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_mad_all_actions.pickle\", \"wb\")) \r\n",
        "        \r\n",
        "    \r\n",
        "\r\n",
        "    if scheduler == \"dqn\":\r\n",
        "        t1 = time.time()\r\n",
        "        dqn_overall[I], dqn_final[I], dqn_all_actions[I] = tf_dqn(I, drones_coverage, folder_name, deployment, packet_update_loss, packet_sample_loss, periodicity, adj_matrix, tx_rx_pairs, tx_users)\r\n",
        "        t2 = time.time()\r\n",
        "        print(\"DQN for \", I, \" users took \", t2-t1, \" seconds to complete\", file=open(folder_name + \"/results.txt\", \"a\"), flush=True)\r\n",
        "        pickle.dump(dqn_overall, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_dqn_overall.pickle\", \"wb\")) \r\n",
        "        pickle.dump(dqn_final, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_dqn_final.pickle\", \"wb\"))\r\n",
        "        pickle.dump(dqn_all_actions, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_dqn_all_actions.pickle\", \"wb\"))\r\n",
        "\r\n",
        "\r\n",
        "    if scheduler == \"c51\":\r\n",
        "        t1 = time.time()\r\n",
        "        c51_overall[I], c51_final[I], c51_all_actions[I] = tf_c51(I, drones_coverage, folder_name, deployment, packet_update_loss, packet_sample_loss, periodicity, adj_matrix)\r\n",
        "        t2 = time.time()\r\n",
        "        print(\"c51 for \", I, \" users took \", t2-t1, \" seconds to complete\", file=open(folder_name + \"/results.txt\", \"a\"), flush=True)\r\n",
        "        pickle.dump(c51_overall, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_c51_overall.pickle\", \"wb\")) \r\n",
        "        pickle.dump(c51_final, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_c51_final.pickle\", \"wb\")) \r\n",
        "        pickle.dump(c51_all_actions, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_c51_all_actions.pickle\", \"wb\")) \r\n",
        "\r\n",
        "    if scheduler == \"sac\":\r\n",
        "        t1 = time.time()\r\n",
        "        #with tf.device('/CPU:0'):\r\n",
        "        greedy_overall[I], greedy_final[I], greedy_all_actions[I] = greedy_scheduling(I, drones_coverage, folder_name, deployment, packet_update_loss, packet_sample_loss, periodicity, adj_matrix, tx_rx_pairs, tx_users)  \r\n",
        "        t2 = time.time()\r\n",
        "        print(\"sac for \", I, \" users took \", t2-t1, \" seconds to complete\", file=open(folder_name + \"/results.txt\", \"a\"), flush=True)\r\n",
        "        pickle.dump(greedy_overall, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_greedy_overall.pickle\", \"wb\")) \r\n",
        "        pickle.dump(greedy_final, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"U_greedy_final.pickle\", \"wb\"))\r\n",
        "        pickle.dump(greedy_all_actions, open(folder_name + \"/\" + deployment + \"/\" + str(I) + \"_greedy_all_actions.pickle\", \"wb\")) \r\n",
        "        \r\n",
        "\r\n",
        "    print(f\"{I} users under {scheduler} scheduling and {deployment} placement are over\\n\\n\", file=open(folder_name + \"/results.txt\", \"a\"), flush=True)\r\n",
        "    print(f\"{I} users under {scheduler} scheduling and {deployment} placement are over\\n\\n\")\r\n",
        "\r\n",
        "#############################################################\r\n",
        "    \r\n",
        "if __name__ == '__main__':\r\n",
        "        \r\n",
        "\r\n",
        "    now_str_1 = now.strftime(\"%Y-%m-%d %H:%M\")\r\n",
        "    folder_name = 'models/' +  now_str_1\r\n",
        "    \r\n",
        "    # print(f\"\\n\\nSTATUS OF GPU : {tf.test.is_built_with_gpu_support() and {tf.test.is_gpu_available()}}\\n\\n\", file = open(folder_name + \"/results.txt\", \"a\"), flush = True)\r\n",
        "    \r\n",
        "    # print(f\"\\n\\nSTATUS OF GPU : {tf.test.is_built_with_gpu_support() and {tf.test.is_gpu_available()}}\\n\\n\")\r\n",
        "    \r\n",
        "    folder_name_MDS = folder_name + \"/MDS\"\r\n",
        "    folder_name_random = folder_name + \"/RP\" ## RP means random placement\r\n",
        "\r\n",
        "    if not os.path.isdir(folder_name):\r\n",
        "        os.makedirs(folder_name)\r\n",
        "        os.makedirs(folder_name_MDS)\r\n",
        "        os.makedirs(folder_name_random) \r\n",
        "        \r\n",
        "    print(\"execution started at \", now_str_1, file = open(folder_name + \"/results.txt\", \"a\"), flush = True)\r\n",
        "\r\n",
        "    print(\"num_iterations = \",num_iterations, \", random_episodes = \", random_episodes,\", DL_capacity = \", DL_capacity, \", UL_capacity = \", UL_capacity,\",  MAX_STEPS = \", MAX_STEPS, \" gamma = \", set_gamma, \", learning_rate = \", learning_rate, \", fc_layer_params = \", fc_layer_params, \", replay_buffer_capacity = \", replay_buffer_capacity, \", coverage_capacity = \", coverage_capacity, \", L = \", L, \", B = \", B, \", R = \", R, \", r = \", r,  \"\\n\", file = open(folder_name + \"/results.txt\", \"a\"), flush = True)\r\n",
        "\r\n",
        "# export LD_LIBRARY_PATH = /path/to/conda/envs/tf1/lib conda create --name tf1 --clone tf\r\n",
        "\r\n",
        "    deployments = [\"RP\"] #, \"RP\"] #, \"MDS\"]\r\n",
        "    \r\n",
        "    schedulers  = [\"sac\"] ##     scheduler_options  = [\"random\", \"greedy\", \"MAD\", \"dqn\", \"c51\", \"sac\"]\r\n",
        "    \r\n",
        "    limit_memory = False ## enabling this makes the code not being able to find CUDA device\r\n",
        "    \r\n",
        "#############################\r\n",
        "\r\n",
        "    experiment = 1\r\n",
        "\r\n",
        "    if experiment == 1:\r\n",
        "        test_case           = True\r\n",
        "        packet_loss         = False\r\n",
        "        periodic_generation = False\r\n",
        "\r\n",
        "    elif experiment == 2:\r\n",
        "        test_case           = True\r\n",
        "        packet_loss         = True\r\n",
        "        periodic_generation = False\r\n",
        "        \r\n",
        "    elif experiment == 3:\r\n",
        "        test_case           = False\r\n",
        "        packet_loss         = False\r\n",
        "        periodic_generation = False\r\n",
        "\r\n",
        "    elif experiment == 4:\r\n",
        "        test_case           = False\r\n",
        "        packet_loss         = True\r\n",
        "        periodic_generation = False\r\n",
        "\r\n",
        "    elif experiment == 5:\r\n",
        "        test_case           = True\r\n",
        "        packet_loss         = False\r\n",
        "        periodic_generation = True\r\n",
        "\r\n",
        "    elif experiment == 6:\r\n",
        "        test_case           = True\r\n",
        "        packet_loss         = True\r\n",
        "        periodic_generation = True\r\n",
        "        \r\n",
        "    elif experiment == 7:\r\n",
        "        test_case           = False\r\n",
        "        packet_loss         = False\r\n",
        "        periodic_generation = True\r\n",
        "\r\n",
        "    elif experiment == 8:\r\n",
        "        test_case           = False\r\n",
        "        packet_loss         = True\r\n",
        "        periodic_generation = True\r\n",
        "    \r\n",
        "    if test_case:\r\n",
        "        users = [3] ## will get changed accordingly inside the loop above\r\n",
        "    else:\r\n",
        "        users = [8,10]\r\n",
        "\r\n",
        "#############################\r\n",
        "\r\n",
        "    \r\n",
        "    arguments = list(itertools.product(deployments, users, schedulers)) ## deployment, I, scheduler\r\n",
        "    \r\n",
        "    dqn_overall = {}\r\n",
        "    dqn_final = {}\r\n",
        "    dqn_all_actions = {}\r\n",
        "    \r\n",
        "    c51_overall = {}\r\n",
        "    c51_final = {}\r\n",
        "    c51_all_actions = {}\r\n",
        "    \r\n",
        "    reinforce_overall = {}\r\n",
        "    reinforce_final = {}\r\n",
        "    reinforce_all_actions = {}\r\n",
        "    \r\n",
        "    random_overall = {} ## sum of age at destination nodes for all of the MAX_STEPS time steps\r\n",
        "    random_final   = {} ## sum of age at destination nodes for step =  MAX_STEPS i.e. last time step\r\n",
        "    random_all_actions = {}\r\n",
        "    \r\n",
        "    greedy_overall = {}\r\n",
        "    greedy_final   = {}\r\n",
        "    greedy_all_actions = {}\r\n",
        "    \r\n",
        "    mad_overall = {}\r\n",
        "    mad_final   = {}\r\n",
        "    mad_all_actions = {}\r\n",
        "\r\n",
        "    pool = mp.Pool(mp.cpu_count())\r\n",
        "    print(f\"pool is {pool} \\n\\n\", file = open(folder_name + \"/results.txt\", \"a\"))\r\n",
        "    print(f\"experiment is {experiment} with test_case = {test_case}, packet_loss = {packet_loss}, periodic_generation = {periodic_generation}\", file = open(folder_name + \"/results.txt\", \"a\"))\r\n",
        "    print(f\"experiment is {experiment} with test_case = {test_case}, packet_loss = {packet_loss}, periodic_generation = {periodic_generation}\")\r\n",
        "\r\n",
        "    distributed_run(arguments)\r\n",
        "\r\n",
        "    pool.close()    \r\n",
        "\r\n",
        "\r\n",
        "from google.colab import files\r\n",
        "!ls\r\n",
        "!zip -r /content/sac.zip /content/models\r\n",
        "# !ls\r\n",
        "files.download(\"/content/sac.zip\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content\n",
            "Collecting tf-agents\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/cd/a0710b1caae042b7a4d54fc74073fb4df7adf073934798443bdc0059813a/tf_agents-0.7.1-py3-none-any.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.17.3)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (3.7.4.3)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-probability>=0.12.1 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.12.1)\n",
            "Requirement already satisfied: pillow>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (7.0.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (3.12.4)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (0.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-agents) (1.12.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.17.0->tf-agents) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.17.0->tf-agents) (1.4.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.12.1->tf-agents) (0.3.3)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.12.1->tf-agents) (0.1.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.12.1->tf-agents) (4.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.11.3->tf-agents) (51.3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17.0->tf-agents) (0.16.0)\n",
            "Installing collected packages: tf-agents\n",
            "Successfully installed tf-agents-0.7.1\n",
            "Collecting dm-reverb[tensorflow]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/63/cda3f58eff31ab5041551642498558bd78322c62580f1dc766badaac0dcf/dm_reverb-0.2.0-cp36-cp36m-manylinux2010_x86_64.whl (6.3MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3MB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from dm-reverb[tensorflow]) (0.1.5)\n",
            "Requirement already satisfied: portpicker in /usr/local/lib/python3.6/dist-packages (from dm-reverb[tensorflow]) (1.3.1)\n",
            "Requirement already satisfied: tensorflow>=2.4.0; extra == \"tensorflow\" in /usr/local/lib/python3.6/dist-packages (from dm-reverb[tensorflow]) (2.4.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from dm-tree->dm-reverb[tensorflow]) (1.15.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.32.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (3.3.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.12.1)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (2.4.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (0.36.2)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (0.3.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (0.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.12)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (3.12.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (51.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.17.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (3.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (2020.12.5)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.4.0; extra == \"tensorflow\"->dm-reverb[tensorflow]) (0.4.8)\n",
            "Installing collected packages: dm-reverb\n",
            "Successfully installed dm-reverb-0.2.0\n",
            "GPUs are [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "\n",
            "\n",
            " 1 Physical GPUs, 1 Logical GPU\n",
            "\n",
            "\n",
            "experiment is 1 with test_case = True, packet_loss = False, periodic_generation = False\n",
            "passed arguments are [('RP', 3, 'sac')]\n",
            "\n",
            "\n",
            "greedy started for 3 users , coverage = [[10, 11, 12]] with update_loss = {(10, 11): -1, (10, 12): -1, (11, 10): -1, (11, 12): -1, (12, 10): -1, (12, 11): -1}, sample_loss = {10: -1, 11: -1, 12: -1}, periodicity = {10: 1, 11: 1, 12: 1}, tx_rx_pairs = [[10, 11], [10, 12], [11, 10], [11, 12], [12, 10], [12, 11]], tx_users = [10, 11, 12]  and RP deployment, UL_capacity = 2, DL_capacity = 1 and RP deployment\n",
            "\n",
            "greedy scheduling  RP  placement,  3  users - avg of final_step_rewards =  28.9915  MIN and MAX of final_step_rewards =  27 ,  33  and avg of overall_ep_reward =  247.9869  : end with final state of  [1 1 1 1 1 1 1 1 1 1]  with shape  (10,)\n",
            "3 users under sac scheduling and RP placement are over\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}